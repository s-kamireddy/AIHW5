{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr5zZLXJnz5T"
      },
      "outputs": [],
      "source": [
        "# import required libraries from titanic example\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import Normalizer, LabelEncoder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpZNKRYlslac",
        "outputId": "80d54530-30ab-408c-e9d6-636899a8c75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/emmarex/plantdisease?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 658M/658M [00:04<00:00, 143MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npQsVTuByU-t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6EZ92e-5KUc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNJO6rGA5Kq_"
      },
      "source": [
        "Creating a custom data loader class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoLT6X91uNxe"
      },
      "outputs": [],
      "source": [
        "class PlantDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for loading plant disease images\"\"\"\n",
        "    def __init__(self, imagepaths, labels, transform=None):\n",
        "        self.imagepaths = imagepaths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.imagepaths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load the image and apply transformations\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, torch.tensor(label, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_4w6G9mFyX9"
      },
      "outputs": [],
      "source": [
        "path = path+'/PlantVillage'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt24tG-O-Vp1"
      },
      "source": [
        "Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSzrRteh-XyP"
      },
      "outputs": [],
      "source": [
        "image_paths, labels = [], []\n",
        "\n",
        "for disease in os.listdir(path):\n",
        "    disease_path = os.path.join(path, disease)\n",
        "\n",
        "    for image in os.listdir(disease_path):\n",
        "      if image.startswith(\".\"):\n",
        "        continue\n",
        "      image_path = os.path.join(disease_path, image)\n",
        "      if image_path.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "        image_paths.append(image_path)\n",
        "        labels.append(disease)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "class_names = list(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWiTcncqFsTJ",
        "outputId": "575ea8d6-06a4-46e2-91f9-fb9f279f475b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/root/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus/1666ae7f-31f9-4faf-8b60-40a1ded014ea___YLCV_GCREC 2236.JPG', '/root/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus/4254afe0-7830-4ffa-bd0d-5d298280275c___UF.GRC_YLCV_Lab 01523.JPG', '/root/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus/7e3bc5f6-9890-4e2e-90a3-cd394eedb6c5___YLCV_NREC 2412.JPG', '/root/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus/13fb8aaa-4db1-405e-86b9-dc482b10b7d8___UF.GRC_YLCV_Lab 02339.JPG', '/root/.cache/kagglehub/datasets/emmarex/plantdisease/versions/1/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus/1559bd4d-251e-4568-9e25-08c1e8fa3674___YLCV_NREC 2384.JPG']\n",
            "[12 12 12 12 12]\n"
          ]
        }
      ],
      "source": [
        "print(image_paths[:5])\n",
        "print(labels[5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYKlWOF3-L5Z",
        "outputId": "a98f91b5-9ef6-4dc1-f8d8-6bab528beaf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 16510\n",
            "Test size: 4128\n"
          ]
        }
      ],
      "source": [
        "#train test split\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(\"Train size:\", len(train_paths))\n",
        "print(\"Test size:\", len(test_paths))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJLNSSPMGjGE"
      },
      "outputs": [],
      "source": [
        "#apply transformations to avoid model to avoid overfit\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDhdOaMMkhll"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riQO_U8VGlyo"
      },
      "outputs": [],
      "source": [
        "train_dataset = PlantDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = PlantDataset(test_paths, test_labels, transform=valid_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bZFkjUFCoKC"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRVBomLiCtQo"
      },
      "outputs": [],
      "source": [
        "class ImageClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 256, 5)\n",
        "        self.conv3 = nn.Conv2d(256, 128, 5)\n",
        "        self.conv4 = nn.Conv2d(128, 16, 5)\n",
        "        self.fc1 = nn.Linear(1600, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8Abhw665btr"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ImageClassifier(num_classes=len(class_names)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4qQiECd5mrD"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCQ12z4d58tD",
        "outputId": "c5d3983b-e072-498c-eaba-aa2dc95f27d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Batch 0/516, Loss: 2.684429883956909\n",
            "Epoch 1/10, Batch 100/516, Loss: 1.9450310468673706\n",
            "Epoch 1/10, Batch 200/516, Loss: 1.882965087890625\n",
            "Epoch 1/10, Batch 300/516, Loss: 1.393473744392395\n",
            "Epoch 1/10, Batch 400/516, Loss: 1.1970959901809692\n",
            "Epoch 1/10, Batch 500/516, Loss: 1.1970373392105103\n",
            "Epoch 2/10, Batch 0/516, Loss: 0.9963145852088928\n",
            "Epoch 2/10, Batch 100/516, Loss: 0.9472709894180298\n",
            "Epoch 2/10, Batch 200/516, Loss: 1.4212031364440918\n",
            "Epoch 2/10, Batch 300/516, Loss: 0.862163782119751\n",
            "Epoch 2/10, Batch 400/516, Loss: 0.7142228484153748\n",
            "Epoch 2/10, Batch 500/516, Loss: 0.5858836770057678\n",
            "Epoch 3/10, Batch 0/516, Loss: 0.7702586054801941\n",
            "Epoch 3/10, Batch 100/516, Loss: 0.8765339255332947\n",
            "Epoch 3/10, Batch 200/516, Loss: 0.7148088216781616\n",
            "Epoch 3/10, Batch 300/516, Loss: 0.9208993315696716\n",
            "Epoch 3/10, Batch 400/516, Loss: 0.926418662071228\n",
            "Epoch 3/10, Batch 500/516, Loss: 0.6222499012947083\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "    train_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{10}, Batch {i}/{len(train_loader)}, Loss: {loss.item()}\")\n",
        "            train_loss = 0.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv1yrUICSVVA",
        "outputId": "aa59f381-e546-4d5a-fd6e-b809704fcdd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.7573, Test Accuracy: 74.03%\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru34dz8AObKy"
      },
      "source": [
        "Task1 Part 2: VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaCW9PmtoR4I",
        "outputId": "342b6a49-c63a-4c0a-a7a4-0fde3d45421d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 166MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "num_features = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_features, len(class_names))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "doe8cUWJWgB6",
        "outputId": "6e1a4c64-e27b-46fc-9693-c9006bfabfcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Batch 0/516, Loss: 2.766028642654419\n",
            "Epoch 1/10, Batch 100/516, Loss: 2.7980244159698486\n",
            "Epoch 1/10, Batch 200/516, Loss: 2.8107030391693115\n",
            "Epoch 1/10, Batch 300/516, Loss: 2.9490106105804443\n",
            "Epoch 1/10, Batch 400/516, Loss: 2.705845832824707\n",
            "Epoch 1/10, Batch 500/516, Loss: 2.7630910873413086\n",
            "Epoch 2/10, Batch 0/516, Loss: 2.802272081375122\n",
            "Epoch 2/10, Batch 100/516, Loss: 2.807744264602661\n",
            "Epoch 2/10, Batch 200/516, Loss: 2.7819747924804688\n",
            "Epoch 2/10, Batch 300/516, Loss: 2.843998432159424\n",
            "Epoch 2/10, Batch 400/516, Loss: 2.887906551361084\n",
            "Epoch 2/10, Batch 500/516, Loss: 2.7316181659698486\n",
            "Epoch 3/10, Batch 0/516, Loss: 2.713881254196167\n",
            "Epoch 3/10, Batch 100/516, Loss: 2.809537172317505\n",
            "Epoch 3/10, Batch 200/516, Loss: 2.72906231880188\n",
            "Epoch 3/10, Batch 300/516, Loss: 2.838984251022339\n",
            "Epoch 3/10, Batch 400/516, Loss: 2.769102096557617\n",
            "Epoch 3/10, Batch 500/516, Loss: 2.7028422355651855\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for epoch in range(3):\n",
        "  train_loss = 0.0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{10}, Batch {i}/{len(train_loader)}, Loss: {loss.item()}\")\n",
        "            train_loss = 0.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DRBdYkvNtHnN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3QBRinNKe0UD",
        "outputId": "059dbffc-f138-4bab-f4d3-c5e406d21345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.7880, Test Accuracy: 6.64%\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG performs far less accurately due to overfit"
      ],
      "metadata": {
        "id": "4iVpFmzGCMfZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwX39-RJiIAP"
      },
      "source": [
        "Part 3: adding diversity to the dataset and repeating part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-keiRtYTk3oA"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jGJbD8QEmRCn"
      },
      "outputs": [],
      "source": [
        "train_dataset = PlantDataset(train_paths, train_labels, transform=train_transform)\n",
        "test_dataset = PlantDataset(test_paths, test_labels, transform=valid_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1kg9s3N9oqdv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R5tgDovAqH7v"
      },
      "outputs": [],
      "source": [
        "model = ImageClassifier(num_classes=len(class_names)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5ziNrC8YpzbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edaa3e2-556f-4c13-8fc6-ba9e49f5d9d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch 0/516, Loss: 2.702105760574341\n",
            "Epoch 1/10, Batch 100/516, Loss: 2.722494125366211\n",
            "Epoch 1/10, Batch 200/516, Loss: 2.699586868286133\n",
            "Epoch 1/10, Batch 300/516, Loss: 2.7081170082092285\n",
            "Epoch 1/10, Batch 400/516, Loss: 2.7087597846984863\n",
            "Epoch 1/10, Batch 500/516, Loss: 2.6999173164367676\n",
            "Epoch 2/10, Batch 0/516, Loss: 2.714127779006958\n",
            "Epoch 2/10, Batch 100/516, Loss: 2.7021172046661377\n",
            "Epoch 2/10, Batch 200/516, Loss: 2.6997079849243164\n",
            "Epoch 2/10, Batch 300/516, Loss: 2.7157630920410156\n",
            "Epoch 2/10, Batch 400/516, Loss: 2.710273265838623\n",
            "Epoch 2/10, Batch 500/516, Loss: 2.700863838195801\n",
            "Epoch 3/10, Batch 0/516, Loss: 2.7259464263916016\n",
            "Epoch 3/10, Batch 100/516, Loss: 2.7177107334136963\n",
            "Epoch 3/10, Batch 200/516, Loss: 2.723723888397217\n",
            "Epoch 3/10, Batch 300/516, Loss: 2.713331460952759\n",
            "Epoch 3/10, Batch 400/516, Loss: 2.719778537750244\n",
            "Epoch 3/10, Batch 500/516, Loss: 2.722012758255005\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "    train_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{10}, Batch {i}/{len(train_loader)}, Loss: {loss.item()}\")\n",
        "            train_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4jUVB5ketAN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11a3177-d57c-4804-ce97-7adff7ca083d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.7070, Test Accuracy: 11.02%\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding diversity makes model performance worse, as the increased diversity in training data is not applicable to the test data"
      ],
      "metadata": {
        "id": "U6ZxXuGjCRU1"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}